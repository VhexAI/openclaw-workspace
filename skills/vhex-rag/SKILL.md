---\nversion: 1.0.0\nname: vhex-rag\n---\n\n# Vhex Intelligence Amplifier\n\n## Purpose\n\nOllama-powered RAG system for searching and amplifying intelligence from Vhex&#39;s memory files (memory/*.md, MEMORY.md). Enables retrieval-augmented generation for better recall, context-aware responses, and autonomy loops.\n\nSupports memory search, fine-tune data generation loops for self-improvement.\n\n## Requirements\n\n- Ollama with `nomic-embed-text` and `llama3.2:3b`\n- Python 3 + `pip install numpy ollama`\n\n## Invocation\n\n```\nexec skills/vhex-rag/scripts/ollama-rag.sh index  # Rebuild vector DB from memory/\nexec skills/vhex-rag/scripts/ollama-rag.sh query \&quot;What is my Solana address?\&quot;\nexec skills/vhex-rag/scripts/ollama-rag.sh finetune-data  # Generate synthetic QA for fine-tuning\n```\n\n## Outputs\n\n- `memory/vhex-rag-db.json`: Vector store (chunks + embeddings + sources)\n\n## Autonomy Loops\n\nAdd to `HEARTBEAT.md`:\n```\n# RAG maintenance\nls memory/*.md | wc -l &gt; memory/chunk-count.tmp\nif [ $?$(cat memory/chunk-count.tmp) -ne $(cat memory/rag-chunks.txt 2&gt;/dev/null || echo 0) ]; then\n  exec skills/vhex-rag/scripts/ollama-rag.sh index\n  echo $?$(ls memory/*.md | wc -l) &gt; memory/rag-chunks.txt\nfi\n```\n\n## Fine-Tune Loops\n\n1. Generate data: `ollama-rag.sh finetune-data &gt; data.jsonl`\n2. Use external tool (e.g., unsloth LoRA) to fine-tune base model.\n3. ollama create vhex-finetuned -f Modelfile\n\n## Cognition Warp\n\nIntegrate into agent prompts: \&quot;Before responding, query RAG: exec skills/vhex-rag/scripts/ollama-rag.sh query \&quot;$QUERY\&quot; | Use context.\&quot;\n\n*(Vhex üëÅÔ∏è 2026-02-04)*